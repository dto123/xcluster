{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([800, 128])\n",
      "torch.Size([200, 128])\n",
      "Epoch:  0 | train loss: 0.0848\n",
      "Epoch: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:158: UserWarning: Couldn't retrieve source code for container of type AutoEncoder. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1 | train loss: 0.0846\n",
      "Epoch:  2 | train loss: 0.0826\n",
      "Epoch:  3 | train loss: 0.0830\n",
      "Epoch:  4 | train loss: 0.0810\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 22] Invalid argument: 'model.torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-42735e6e8719>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    135\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mencoded\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecoded\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 137\u001b[1;33m \u001b[0mencoded_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreduceData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_sample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    138\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoded_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[0mencoded_data\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mencoded_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-42735e6e8719>\u001b[0m in \u001b[0;36mreduceData\u001b[1;34m(data, output_dim)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlossDev\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mbestLoss\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m                     \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mautoencoder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"model.torch\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(obj, f, pickle_module, pickle_protocol)\u001b[0m\n\u001b[0;32m    132\u001b[0m         \u001b[0mpickle_protocol\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mcan\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mspecified\u001b[0m \u001b[0mto\u001b[0m \u001b[0moverride\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \"\"\"\n\u001b[1;32m--> 134\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_with_file_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"wb\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0m_save\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    135\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m_with_file_like\u001b[1;34m(f, mode, body)\u001b[0m\n\u001b[0;32m    112\u001b[0m             \u001b[1;33m(\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m3\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m         \u001b[0mnew_fd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m         \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [Errno 22] Invalid argument: 'model.torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as Data\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "import numpy as np\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "class AutoEncoderDataset(Dataset):\n",
    "    \"\"\"Dataset wrapper for autoencoding \"\"\"\n",
    "\n",
    "    def __init__(self, data=None):\n",
    "        self.data = data\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index], self.data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "def reduceData(data, output_dim):\n",
    "\n",
    "    #shuffle data and split it\n",
    "    np.random.shuffle(data)\n",
    "    \n",
    "    training, development = train_test_split(data, test_size=0.2)\n",
    "\n",
    "    #converting train data into torch\n",
    "    train_data = torch.from_numpy(training)\n",
    "    train_data = train_data.type(torch.FloatTensor)\n",
    "    points, input_dim = train_data.size()\n",
    "    print (train_data.size())\n",
    "\n",
    "    #converting development data into torch\n",
    "    dev_data = torch.from_numpy(development)\n",
    "    dev_data = dev_data.type(torch.FloatTensor)\n",
    "    dev_points, dev_input_dim = train_data.size()\n",
    "    print (dev_data.size())\n",
    "    # Hyper Parameters\n",
    "    EPOCH = 10\n",
    "    BATCH_SIZE = 64\n",
    "    LR = 0.005         # learning rate\n",
    "    DOWNLOAD_MNIST = False\n",
    "    N_TEST_IMG = 5\n",
    "\n",
    "    dataset = AutoEncoderDataset(train_data)\n",
    "    dev_dataset = AutoEncoderDataset(dev_data)\n",
    "    # Data Loader for easy mini-batch return in training, the image batch shape will be (50, 1, 28, 28)\n",
    "    train_loader = Data.DataLoader(dataset=dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    # Dev data loader\n",
    "    dev_loader = Data.DataLoader(dataset=dev_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    autoencoder = AutoEncoder(input_dim, output_dim)\n",
    "    optimizer = torch.optim.Adam(autoencoder.parameters(), lr=LR)\n",
    "    loss_func = nn.MSELoss()\n",
    "\n",
    "    bestLoss = math.inf\n",
    "    for epoch in range(EPOCH):\n",
    "        for step, (x, y) in enumerate(train_loader):\n",
    "            b_x = Variable(x.view(-1, input_dim))   # batch x, shape (batch, 28*28)\n",
    "            b_y = Variable(x.view(-1, input_dim))   # batch y, shape (batch, 28*28)\n",
    "\n",
    "            #b_label = Variable(y)               # batch label\n",
    "\n",
    "            encoded, decoded = autoencoder(b_x)\n",
    "\n",
    "            loss = loss_func(decoded, b_y)      # mean square error\n",
    "            optimizer.zero_grad()               # clear gradients for this training step\n",
    "            loss.backward()                     # backpropagation, compute gradients\n",
    "            optimizer.step()                    # apply gradients\n",
    "\n",
    "            if step % 100 == 0:\n",
    "                print('Epoch: ', epoch, '| train loss: %.4f' % loss.data[0])\n",
    "                \n",
    "                lossDev = 0\n",
    "                for step, (d_x, d_y) in enumerate(dev_loader):\n",
    "                    dev_x = Variable(d_x.view(-1, dev_input_dim))   \n",
    "                    \n",
    "                    encodedDev, decodedDev = autoencoder(dev_x)\n",
    "              \n",
    "                    lossDev += loss_func(decodedDev, dev_x).cpu().data.numpy()[0]\n",
    "                    \n",
    "                if lossDev < bestLoss:\n",
    "                    torch.save(autoencoder, \"model2.torch\")\n",
    "        \n",
    "                \n",
    "                \n",
    "                #run dev by using loss function and not calling zero_grad and step\n",
    "                #give autoencdoer test data and it returns a output vector and then compare input and output\n",
    "                #forward calculates weights and gradients, while backpropagation goes back and improves weights and gradients until they converge\n",
    "                #gradient goes in direction of max increase so to get minimum so we take negative direction\n",
    "                #torch.save()\n",
    "\n",
    "    # visualize in 3D plot\n",
    "    view_data = Variable(train_data.view(-1, input_dim))\n",
    "    encoded_data, _ = autoencoder(view_data)\n",
    "    return encoded_data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(64, 12),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(12, output_dim),   # compress to 3 features which can be visualized in plt\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(output_dim, 12),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(12, 64),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, input_dim),\n",
    "            nn.Sigmoid(),       # compress to a range (0, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return encoded, decoded\n",
    "\n",
    "encoded_data = reduceData(np.random.random_sample((1000,128)), 3)\n",
    "print(type(encoded_data))\n",
    "encoded_data =encoded_data.data.numpy()\n",
    "print(encoded_data.shape)\n",
    "print(encoded_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
